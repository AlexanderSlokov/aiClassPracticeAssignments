{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMe36OHf1HrDWxcWu8l25AQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexanderSlokov/aiClassPracticeAssignments/blob/main/AIweek8_PreprocessWithScalar_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "mt0NBgXBEM6H"
      },
      "outputs": [],
      "source": [
        "#libraries of different datasets to train\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "# In machine learning, Output can only have 1 bit but have to display 3 values (0,1,2) => one-hot-encoding make it to the string of 0 and 1 like 0->100 ; 1->010 ; ... make the output values more acurate \n",
        "# StandardScaler makes data \"cung chieu cao\" to be able to train the dataset\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The name of vars must be like this, other ways will not be recognized \n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "print(X[:5])\n",
        "print(y[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4A8eDLMHM6e",
        "outputId": "4fc6de84-85fc-473e-e228-434174d1d526"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n",
            "[0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split datasets to 2 parts: training and testing in order 7:3\n",
        "X_train, X_test, y_train, y_test = train_test_split( X,y,test_size=0.3)"
      ],
      "metadata": {
        "id": "G21SCZ9uHzrJ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "nz1vcIhDIw4K"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Max_iter = số lần học, eta0 = learning rate \n",
        "model = Perceptron (max_iter = 40, eta0 = 0.1, random_state = 0)\n",
        "model.fit( X_train, y_train )\n",
        "y_predict = model.predict(X_test)\n",
        "\n",
        "print(y_test)\n",
        "print(y_predict)\n",
        "print('Prediction accuracy when did not use Scaler is:', accuracy_score(y_test, y_predict))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d33KvD8JLzZ",
        "outputId": "4df9815b-3de1-4f16-d515-863a165decd5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 0 1 2 0 2 0 1 2 2 0 2 1 2 0 2 1 0 1 0 1 0 2 0 1 1 0 0 0 0 0 1 0 1 0 1\n",
            " 1 0 2 0 1 2 2 2]\n",
            "[0 2 0 2 1 0 2 0 1 2 2 0 2 1 2 0 2 1 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1\n",
            " 1 0 2 0 1 2 2 2]\n",
            "Prediction accuracy when did not use Scaler is: 0.9111111111111111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Perceptron (max_iter = 40, eta0 = 0.1, random_state = 0)\n",
        "model.fit( X_train_std, y_train )\n",
        "y_predict = model.predict(X_test_std)\n",
        "\n",
        "print(y_test)\n",
        "print(y_predict)\n",
        "print('Prediction accuracy when  use Scaler is:', accuracy_score(y_test, y_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ufU3mxrLPON",
        "outputId": "ee379314-896e-42e2-a32a-759eef7933c3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 0 1 2 0 2 0 1 2 2 0 2 1 2 0 2 1 0 1 0 1 0 2 0 1 1 0 0 0 0 0 1 0 1 0 1\n",
            " 1 0 2 0 1 2 2 2]\n",
            "[0 2 0 2 2 0 2 0 1 2 2 0 2 2 2 0 2 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1\n",
            " 1 0 2 0 1 2 2 2]\n",
            "Prediction accuracy when  use Scaler is: 0.8666666666666667\n"
          ]
        }
      ]
    }
  ]
}